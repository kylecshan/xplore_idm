{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.dataset as dataset\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER = 'E:/xplore_data/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=100, out_features=20, bias=True)\n",
       "    (3): Identity()\n",
       "    (4): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "net = initialize_model2()\n",
    "net.classifier = nn.Sequential(\n",
    "    nn.Linear(net.n_features, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 20),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(20, 7)\n",
    ")\n",
    "n_features = 20\n",
    "\n",
    "SAVED_MODEL_PATH = 'checkpoints/vgg11bn_4_e2e_all'\n",
    "net.load_state_dict(torch.load(SAVED_MODEL_PATH))\n",
    "\n",
    "# Freeze layers\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# We just want to apply the feature extractor for now\n",
    "net.classifier[3] = nn.Identity()\n",
    "net.classifier[4] = nn.Identity()\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "DATA_FILE = 'E:/xplore_data/data/images.h5'\n",
    "HEALTH_FILE = 'data/dhs_gps.csv'\n",
    "dimages = TestDataset2(DATA_FILE, HEALTH_FILE)\n",
    "dimagesloader = torch.utils.data.DataLoader(dimages, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature extractor to the dataset\n",
    "n = len(dimages)\n",
    "extracted_features = torch.zeros(n, n_features)\n",
    "lights = torch.zeros(n, 3)\n",
    "c_ids = np.zeros(n)\n",
    "vac_rates = np.zeros((n,11))\n",
    "i = 0\n",
    "# Iterate over data.\n",
    "net.to(device)\n",
    "for x, lt, z in dimagesloader:\n",
    "    x = x.to(device)\n",
    "    j = i + x.shape[0]\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = net(x)\n",
    "        extracted_features[i:j, :] = torch.squeeze(outputs).cpu()\n",
    "        c_ids[i:j] = z[:, 0]\n",
    "        vac_rates[i:j] = z[:, 14:25]\n",
    "        lt = torch.reshape(lt, [-1, 333*333])\n",
    "        lights[i:j, 0] = torch.sum(lt == 0, axis=1)\n",
    "        lights[i:j, 1] = torch.sum(lt == 1, axis=1)\n",
    "        lights[i:j, 2] = torch.sum(lt == 2, axis=1)\n",
    "    i += x.shape[0]\n",
    "extracted_features = extracted_features.numpy()\n",
    "c_ids = c_ids.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = lights.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(extracted_features, 'data/features_e2e.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset of built environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = torch.load('data/features_e2e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILT_FOLDER = 'E:/xplore_data/built/'\n",
    "counts = np.zeros((889, 6), np.int)\n",
    "for i, file in enumerate(os.listdir(BUILT_FOLDER)):\n",
    "    img = load_file(BUILT_FOLDER, file)\n",
    "    val, ct = torch.unique(img, return_counts=True)\n",
    "    val = val.numpy().astype(np.int)-1\n",
    "    ct = ct.numpy()\n",
    "    counts[i, val] = ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 6)\n",
      "(889, 20)\n"
     ]
    }
   ],
   "source": [
    "print(counts.shape)\n",
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "# 0: water, 1: not built, 2-5: built from various times\n",
    "built = counts[:, 2:].sum(axis=1)\n",
    "water = counts[:, 0]\n",
    "recent = counts[:, 2]\n",
    "print(built.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def show_r2(x, y):\n",
    "    reg = LinearRegression()\n",
    "    x = x.reshape(889, -1)\n",
    "    y = y.reshape(889, -1)\n",
    "    reg.fit(x, y)\n",
    "    print('%.3f' % reg.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.320\n",
      "0.357\n",
      "0.422\n",
      "0.376\n",
      "0.306\n",
      "0.358\n",
      "0.396\n",
      "0.323\n",
      "0.379\n",
      "0.399\n",
      "0.344\n",
      "0.350\n",
      "0.303\n",
      "0.363\n",
      "0.329\n",
      "0.418\n",
      "0.379\n",
      "0.319\n",
      "0.339\n",
      "0.378\n"
     ]
    }
   ],
   "source": [
    "# r2 between features and built \n",
    "from scipy.stats import pearsonr\n",
    "for i in range(20):\n",
    "    show_r2(built, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.001\n",
      "0.002\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Features and water\n",
    "for i in range(20):\n",
    "    show_r2(water, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 2)\n"
     ]
    }
   ],
   "source": [
    "# vaccs = [0, 1, 2, 3, 4, 5, 9]\n",
    "vaccs = range(11)\n",
    "stats = np.loadtxt('data/dhs_gps.csv', skiprows=1, delimiter=',')\n",
    "vac_rates = stats[:, 14:]\n",
    "lat = stats[:,1:3]\n",
    "print(lat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116\n",
      "0.119\n",
      "0.116\n",
      "0.127\n",
      "0.134\n",
      "0.147\n",
      "0.065\n",
      "0.066\n",
      "0.029\n",
      "0.124\n",
      "0.070\n"
     ]
    }
   ],
   "source": [
    "# Built and vaccination rate\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(built, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.000\n",
      "0.000\n"
     ]
    }
   ],
   "source": [
    "# What about water?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(water, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563\n",
      "0.530\n",
      "0.431\n",
      "0.486\n",
      "0.610\n",
      "0.533\n",
      "0.509\n",
      "0.537\n",
      "0.495\n",
      "0.452\n",
      "0.534\n",
      "0.516\n",
      "0.551\n",
      "0.527\n",
      "0.569\n",
      "0.502\n",
      "0.420\n",
      "0.604\n",
      "0.593\n",
      "0.538\n"
     ]
    }
   ],
   "source": [
    "# What about latitude and features?\n",
    "for i in range(20):\n",
    "    show_r2(lat, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519\n",
      "0.400\n",
      "0.512\n",
      "0.497\n",
      "0.456\n",
      "0.367\n",
      "0.244\n",
      "0.209\n",
      "0.054\n",
      "0.463\n",
      "0.220\n"
     ]
    }
   ],
   "source": [
    "# Latitude and vaccination rate?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(lat, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of latitude and built?\n",
    "lat_built = np.concatenate((lat, built[:, None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731\n",
      "0.727\n",
      "0.688\n",
      "0.701\n",
      "0.760\n",
      "0.732\n",
      "0.736\n",
      "0.708\n",
      "0.714\n",
      "0.688\n",
      "0.720\n",
      "0.706\n",
      "0.705\n",
      "0.726\n",
      "0.735\n",
      "0.749\n",
      "0.648\n",
      "0.766\n",
      "0.771\n",
      "0.746\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    show_r2(lat_built, extracted_features[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.566\n",
      "0.456\n",
      "0.559\n",
      "0.550\n",
      "0.512\n",
      "0.430\n",
      "0.252\n",
      "0.220\n",
      "0.062\n",
      "0.521\n",
      "0.231\n"
     ]
    }
   ],
   "source": [
    "# Latitude and vaccination rate?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(lat_built, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = np.loadtxt('data/dhs_gps.csv', skiprows=1, delimiter=',')\n",
    "resids[:, 14:] = 0\n",
    "for i in range(len(vaccs)):\n",
    "    y = vac_rates[:, vaccs[i]]\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(lat_built, y)\n",
    "    res = y - reg.predict(lat_built)\n",
    "    resids[:, 14+vaccs[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/residuals.csv', resids, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = lights[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.446\n",
      "0.469\n",
      "0.475\n",
      "0.452\n",
      "0.441\n",
      "0.468\n",
      "0.478\n",
      "0.450\n",
      "0.466\n",
      "0.467\n",
      "0.430\n",
      "0.448\n",
      "0.418\n",
      "0.455\n",
      "0.450\n",
      "0.505\n",
      "0.452\n",
      "0.447\n",
      "0.483\n",
      "0.478\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    show_r2(lights, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296\n",
      "0.272\n",
      "0.290\n",
      "0.302\n",
      "0.304\n",
      "0.293\n",
      "0.152\n",
      "0.149\n",
      "0.045\n",
      "0.288\n",
      "0.118\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vaccs)):\n",
    "    show_r2(lights, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 5)\n"
     ]
    }
   ],
   "source": [
    "lat_built_lights = np.concatenate((lat_built, lights), axis=1)\n",
    "print(lat_built_lights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736\n",
      "0.732\n",
      "0.691\n",
      "0.704\n",
      "0.763\n",
      "0.736\n",
      "0.739\n",
      "0.714\n",
      "0.717\n",
      "0.692\n",
      "0.721\n",
      "0.711\n",
      "0.709\n",
      "0.729\n",
      "0.740\n",
      "0.753\n",
      "0.655\n",
      "0.769\n",
      "0.777\n",
      "0.750\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    show_r2(lat_built_lights, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575\n",
      "0.471\n",
      "0.567\n",
      "0.560\n",
      "0.525\n",
      "0.447\n",
      "0.269\n",
      "0.240\n",
      "0.077\n",
      "0.531\n",
      "0.237\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(vaccs)):\n",
    "    show_r2(lat_built_lights, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score as skl_r2\n",
    "from sklearn.model_selection import KFold\n",
    "mode = 'gbm'\n",
    "for i in range(len(vaccs)):\n",
    "    X = lat_built_lights\n",
    "    y = vac_rates[:,vaccs[i]]\n",
    "    n = X.shape[0]\n",
    "    n_train = round(n*.8)\n",
    "    shuffle = np.random.choice(range(n), size=n, replace=False)\n",
    "    idx_train = shuffle[:n_train]\n",
    "    idx_test = shuffle[n_train:]\n",
    "        \n",
    "    if mode == 'gbm':\n",
    "        param_choices = utils.product_dict(\n",
    "                objective=['regression'],\n",
    "                num_leaves=(5, 7, 10),\n",
    "                min_data_in_leaf=(5, 10, 15, 20)\n",
    "                )\n",
    "    elif mode == 'linear':\n",
    "        param_choices = utils.product_dict(\n",
    "        alpha=np.geomspace(.001, 100, num=6)\n",
    "        )\n",
    "    best_params = None\n",
    "    best_mse = 999999999\n",
    "    for params in param_choices:\n",
    "        # Create CV folds\n",
    "        n_fold = 10\n",
    "        kf = KFold(n_splits = n_fold)\n",
    "        pred = np.full_like(y[idx_train], np.nan)\n",
    "        for train_folds, test_folds in kf.split(X[idx_train]):\n",
    "            if mode == 'gbm':\n",
    "                lgb_data = lgb.Dataset(data=X[train_folds], label=y[train_folds])\n",
    "                gbm = lgb.train(params, lgb_data, 100)\n",
    "                fold_pred = gbm.predict(X[test_folds])\n",
    "            elif mode == 'linear':\n",
    "                model = Ridge(**params, max_iter=1000)\n",
    "                model.fit(X[train_folds], y[train_folds])\n",
    "                fold_pred = model.predict(X[test_folds])\n",
    "            pred[test_folds] = fold_pred\n",
    "        avg_mse = np.power(y[idx_train]-pred, 2).mean()\n",
    "        if avg_mse < best_mse:\n",
    "            best_mse = avg_mse\n",
    "            best_params = params\n",
    "#            print('->', end='')\n",
    "#        print(str(params) + ': %.3f' % r2)\n",
    "    \n",
    "    lgb_data = lgb.Dataset(data=X[idx_train], label=y[idx_train])\n",
    "    best_gbm = lgb.train(best_params, lgb_data, 100)\n",
    "    y_pred = best_gbm.predict(X)\n",
    "    mse = [np.power(y[i]-y_pred[i], 2).mean() for i in (idx_train, idx_test)]\n",
    "    r2 = [skl_r2(y[i], y_pred[i]) for i in (idx_train, idx_test)]\n",
    "#    print('train/val/test r2 : %.3f / %.3f / %.3f' % tuple(r2))\n",
    "#    print('train/val/test mse: %.3f / %.3f / %.3f' % tuple(mse))\n",
    "    print(c.ljust(12) + ', %.3f, %.3f , %.3f, %.3f' \n",
    "          % (r2[0], mse[0], r2[1], mse[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
