{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data.dataset as dataset\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from dataset import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FOLDER = 'E:/xplore_data/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(9, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=100, out_features=20, bias=True)\n",
       "    (3): Identity()\n",
       "    (4): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained model\n",
    "net = initialize_model2()\n",
    "net.classifier = nn.Sequential(\n",
    "    nn.Linear(net.n_features, 100),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(100, 20),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(20, 7)\n",
    ")\n",
    "n_features = 20\n",
    "\n",
    "SAVED_MODEL_PATH = 'checkpoints/vgg11bn_4_e2e_all'\n",
    "net.load_state_dict(torch.load(SAVED_MODEL_PATH))\n",
    "\n",
    "# Freeze layers\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# We just want to apply the feature extractor for now\n",
    "net.classifier[3] = nn.Identity()\n",
    "net.classifier[4] = nn.Identity()\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "DATA_FILE = 'E:/xplore_data/data/images.h5'\n",
    "HEALTH_FILE = 'data/dhs_gps.csv'\n",
    "dimages = TestDataset(DATA_FILE, HEALTH_FILE)\n",
    "dimagesloader = torch.utils.data.DataLoader(dimages, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature extractor to the dataset\n",
    "n = len(dimages)\n",
    "extracted_features = torch.zeros(n, n_features)\n",
    "c_ids = np.zeros(n)\n",
    "vac_rates = np.zeros((n,11))\n",
    "i = 0\n",
    "# Iterate over data.\n",
    "net.to(device)\n",
    "for x, _, z in dimagesloader:\n",
    "    x = x.to(device)\n",
    "    j = i + x.shape[0]\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = net(x)\n",
    "        extracted_features[i:j, :] = torch.squeeze(outputs).cpu()\n",
    "        c_ids[i:j] = z[:, 0]\n",
    "        vac_rates[i:j] = z[:, 14:25]\n",
    "    i += x.shape[0]\n",
    "extracted_features = extracted_features.numpy()\n",
    "c_ids = c_ids.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(extracted_features, 'data/features_e2e.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset of built environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = torch.load('data/features_e2e.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILT_FOLDER = 'E:/xplore_data/built/'\n",
    "counts = np.zeros((889, 6), np.int)\n",
    "for i, file in enumerate(os.listdir(BUILT_FOLDER)):\n",
    "    img = load_file(BUILT_FOLDER, file)\n",
    "    val, ct = torch.unique(img, return_counts=True)\n",
    "    val = val.numpy().astype(np.int)-1\n",
    "    ct = ct.numpy()\n",
    "    counts[i, val] = ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 6)\n",
      "(889, 20)\n"
     ]
    }
   ],
   "source": [
    "print(counts.shape)\n",
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889,)\n"
     ]
    }
   ],
   "source": [
    "# 0: water, 1: not built, 2-5: built from various times\n",
    "built = counts[:, 2:].sum(axis=1)\n",
    "water = counts[:, 0]\n",
    "recent = counts[:, 2]\n",
    "print(built.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def show_r2(x, y):\n",
    "    reg = LinearRegression()\n",
    "    x = x.reshape(889, -1)\n",
    "    y = y.reshape(889, -1)\n",
    "    reg.fit(x, y)\n",
    "    print('%.3f' % reg.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.320\n",
      "0.357\n",
      "0.422\n",
      "0.376\n",
      "0.306\n",
      "0.358\n",
      "0.396\n",
      "0.323\n",
      "0.379\n",
      "0.399\n",
      "0.344\n",
      "0.350\n",
      "0.303\n",
      "0.363\n",
      "0.329\n",
      "0.418\n",
      "0.379\n",
      "0.319\n",
      "0.339\n",
      "0.378\n"
     ]
    }
   ],
   "source": [
    "# r2 between features and built \n",
    "from scipy.stats import pearsonr\n",
    "for i in range(20):\n",
    "    show_r2(built, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.001\n",
      "0.000\n",
      "0.001\n",
      "0.002\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "# Features and water\n",
    "for i in range(20):\n",
    "    show_r2(water, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccs = [0, 1, 2, 3, 4, 5, 9]\n",
    "stats = np.loadtxt('data/dhs_gps.csv', skiprows=1, delimiter=',')\n",
    "vac_rates = stats[:, 14:]\n",
    "lat = stats[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.116\n",
      "0.119\n",
      "0.116\n",
      "0.127\n",
      "0.134\n",
      "0.147\n",
      "0.124\n"
     ]
    }
   ],
   "source": [
    "# Built and vaccination rate\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(built, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n",
      "0.000\n"
     ]
    }
   ],
   "source": [
    "# What about water?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(water, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.532\n",
      "0.492\n",
      "0.382\n",
      "0.444\n",
      "0.574\n",
      "0.497\n",
      "0.465\n",
      "0.501\n",
      "0.457\n",
      "0.406\n",
      "0.496\n",
      "0.475\n",
      "0.515\n",
      "0.485\n",
      "0.525\n",
      "0.459\n",
      "0.381\n",
      "0.570\n",
      "0.559\n",
      "0.493\n"
     ]
    }
   ],
   "source": [
    "# What about latitude and features?\n",
    "for i in range(20):\n",
    "    show_r2(lat, extracted_features[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.517\n",
      "0.398\n",
      "0.510\n",
      "0.493\n",
      "0.448\n",
      "0.346\n",
      "0.462\n"
     ]
    }
   ],
   "source": [
    "# Latitude and vaccination rate?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(lat, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combination of latitude and built?\n",
    "lat_built = np.stack((lat, built)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.731\n",
      "0.726\n",
      "0.686\n",
      "0.700\n",
      "0.758\n",
      "0.731\n",
      "0.735\n",
      "0.706\n",
      "0.713\n",
      "0.686\n",
      "0.719\n",
      "0.704\n",
      "0.703\n",
      "0.724\n",
      "0.732\n",
      "0.748\n",
      "0.648\n",
      "0.765\n",
      "0.770\n",
      "0.743\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    show_r2(lat_built, extracted_features[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.565\n",
      "0.455\n",
      "0.558\n",
      "0.550\n",
      "0.512\n",
      "0.427\n",
      "0.519\n"
     ]
    }
   ],
   "source": [
    "# Latitude and vaccination rate?\n",
    "for i in range(len(vaccs)):\n",
    "    show_r2(lat_built, vac_rates[:,vaccs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "resids = np.loadtxt('data/dhs_gps.csv', skiprows=1, delimiter=',')\n",
    "resids[:, 14:] = 0\n",
    "for i in range(len(vaccs)):\n",
    "    y = vac_rates[:, vaccs[i]]\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(lat_built, y)\n",
    "    res = y - reg.predict(lat_built)\n",
    "    resids[:, 14+vaccs[i]] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/residuals.csv', resids, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 9]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
